{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TMDB Prediction - XGBoost.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "name": "python",
      "version": "3.6.4",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yuqiw4/ANLY601Project/blob/master/TMDB_Prediction_XGBoost.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "id": "jnwAK83UimZG",
        "colab_type": "code",
        "colab": {},
        "outputId": "721f8761-97b6-45a8-f351-3c7d6440da7e"
      },
      "cell_type": "code",
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load in \n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the \"../input/\" directory.\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
        "\n",
        "import os\n",
        "print(os.listdir(\"../input\"))\n",
        "\n",
        "# Any results you write to the current directory are saved as output."
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['tmdb-competition-additional-features', 'tmdb-box-office-prediction-more-training-data', 'tmdb-release-dates-per-country', 'tmdb-box-office-prediction']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": true,
        "id": "2zy3691BimZS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns \n",
        "import warnings\n",
        "from tqdm import tqdm\n",
        "from datetime import datetime\n",
        "import json\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import xgboost as xgb\n",
        "import lightgbm as lgb\n",
        "import catboost as cat\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "UOoEM7yKimZV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.preprocessing import scale"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "8cxaarvnimZa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train = pd.read_csv(\"../input/tmdb-box-office-prediction/train.csv\")\n",
        "test = pd.read_csv(\"../input/tmdb-box-office-prediction/test.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "AMxOyE5DimZe",
        "colab_type": "code",
        "colab": {},
        "outputId": "cf1ed869-be27-4db3-9f69-108a197f413b"
      },
      "cell_type": "code",
      "source": [
        "train.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   id    ...      revenue\n",
              "0   1    ...     12314651\n",
              "1   2    ...     95149435\n",
              "2   3    ...     13092000\n",
              "3   4    ...     16000000\n",
              "4   5    ...      3923970\n",
              "\n",
              "[5 rows x 23 columns]"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>belongs_to_collection</th>\n",
              "      <th>budget</th>\n",
              "      <th>genres</th>\n",
              "      <th>homepage</th>\n",
              "      <th>imdb_id</th>\n",
              "      <th>original_language</th>\n",
              "      <th>original_title</th>\n",
              "      <th>overview</th>\n",
              "      <th>popularity</th>\n",
              "      <th>poster_path</th>\n",
              "      <th>production_companies</th>\n",
              "      <th>production_countries</th>\n",
              "      <th>release_date</th>\n",
              "      <th>runtime</th>\n",
              "      <th>spoken_languages</th>\n",
              "      <th>status</th>\n",
              "      <th>tagline</th>\n",
              "      <th>title</th>\n",
              "      <th>Keywords</th>\n",
              "      <th>cast</th>\n",
              "      <th>crew</th>\n",
              "      <th>revenue</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>[{'id': 313576, 'name': 'Hot Tub Time Machine ...</td>\n",
              "      <td>14000000</td>\n",
              "      <td>[{'id': 35, 'name': 'Comedy'}]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>tt2637294</td>\n",
              "      <td>en</td>\n",
              "      <td>Hot Tub Time Machine 2</td>\n",
              "      <td>When Lou, who has become the \"father of the In...</td>\n",
              "      <td>6.575393</td>\n",
              "      <td>/tQtWuwvMf0hCc2QR2tkolwl7c3c.jpg</td>\n",
              "      <td>[{'name': 'Paramount Pictures', 'id': 4}, {'na...</td>\n",
              "      <td>[{'iso_3166_1': 'US', 'name': 'United States o...</td>\n",
              "      <td>2/20/15</td>\n",
              "      <td>93.0</td>\n",
              "      <td>[{'iso_639_1': 'en', 'name': 'English'}]</td>\n",
              "      <td>Released</td>\n",
              "      <td>The Laws of Space and Time are About to be Vio...</td>\n",
              "      <td>Hot Tub Time Machine 2</td>\n",
              "      <td>[{'id': 4379, 'name': 'time travel'}, {'id': 9...</td>\n",
              "      <td>[{'cast_id': 4, 'character': 'Lou', 'credit_id...</td>\n",
              "      <td>[{'credit_id': '59ac067c92514107af02c8c8', 'de...</td>\n",
              "      <td>12314651</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>[{'id': 107674, 'name': 'The Princess Diaries ...</td>\n",
              "      <td>40000000</td>\n",
              "      <td>[{'id': 35, 'name': 'Comedy'}, {'id': 18, 'nam...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>tt0368933</td>\n",
              "      <td>en</td>\n",
              "      <td>The Princess Diaries 2: Royal Engagement</td>\n",
              "      <td>Mia Thermopolis is now a college graduate and ...</td>\n",
              "      <td>8.248895</td>\n",
              "      <td>/w9Z7A0GHEhIp7etpj0vyKOeU1Wx.jpg</td>\n",
              "      <td>[{'name': 'Walt Disney Pictures', 'id': 2}]</td>\n",
              "      <td>[{'iso_3166_1': 'US', 'name': 'United States o...</td>\n",
              "      <td>8/6/04</td>\n",
              "      <td>113.0</td>\n",
              "      <td>[{'iso_639_1': 'en', 'name': 'English'}]</td>\n",
              "      <td>Released</td>\n",
              "      <td>It can take a lifetime to find true love; she'...</td>\n",
              "      <td>The Princess Diaries 2: Royal Engagement</td>\n",
              "      <td>[{'id': 2505, 'name': 'coronation'}, {'id': 42...</td>\n",
              "      <td>[{'cast_id': 1, 'character': 'Mia Thermopolis'...</td>\n",
              "      <td>[{'credit_id': '52fe43fe9251416c7502563d', 'de...</td>\n",
              "      <td>95149435</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3300000</td>\n",
              "      <td>[{'id': 18, 'name': 'Drama'}]</td>\n",
              "      <td>http://sonyclassics.com/whiplash/</td>\n",
              "      <td>tt2582802</td>\n",
              "      <td>en</td>\n",
              "      <td>Whiplash</td>\n",
              "      <td>Under the direction of a ruthless instructor, ...</td>\n",
              "      <td>64.299990</td>\n",
              "      <td>/lIv1QinFqz4dlp5U4lQ6HaiskOZ.jpg</td>\n",
              "      <td>[{'name': 'Bold Films', 'id': 2266}, {'name': ...</td>\n",
              "      <td>[{'iso_3166_1': 'US', 'name': 'United States o...</td>\n",
              "      <td>10/10/14</td>\n",
              "      <td>105.0</td>\n",
              "      <td>[{'iso_639_1': 'en', 'name': 'English'}]</td>\n",
              "      <td>Released</td>\n",
              "      <td>The road to greatness can take you to the edge.</td>\n",
              "      <td>Whiplash</td>\n",
              "      <td>[{'id': 1416, 'name': 'jazz'}, {'id': 1523, 'n...</td>\n",
              "      <td>[{'cast_id': 5, 'character': 'Andrew Neimann',...</td>\n",
              "      <td>[{'credit_id': '54d5356ec3a3683ba0000039', 'de...</td>\n",
              "      <td>13092000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1200000</td>\n",
              "      <td>[{'id': 53, 'name': 'Thriller'}, {'id': 18, 'n...</td>\n",
              "      <td>http://kahaanithefilm.com/</td>\n",
              "      <td>tt1821480</td>\n",
              "      <td>hi</td>\n",
              "      <td>Kahaani</td>\n",
              "      <td>Vidya Bagchi (Vidya Balan) arrives in Kolkata ...</td>\n",
              "      <td>3.174936</td>\n",
              "      <td>/aTXRaPrWSinhcmCrcfJK17urp3F.jpg</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[{'iso_3166_1': 'IN', 'name': 'India'}]</td>\n",
              "      <td>3/9/12</td>\n",
              "      <td>122.0</td>\n",
              "      <td>[{'iso_639_1': 'en', 'name': 'English'}, {'iso...</td>\n",
              "      <td>Released</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Kahaani</td>\n",
              "      <td>[{'id': 10092, 'name': 'mystery'}, {'id': 1054...</td>\n",
              "      <td>[{'cast_id': 1, 'character': 'Vidya Bagchi', '...</td>\n",
              "      <td>[{'credit_id': '52fe48779251416c9108d6eb', 'de...</td>\n",
              "      <td>16000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>[{'id': 28, 'name': 'Action'}, {'id': 53, 'nam...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>tt1380152</td>\n",
              "      <td>ko</td>\n",
              "      <td>마린보이</td>\n",
              "      <td>Marine Boy is the story of a former national s...</td>\n",
              "      <td>1.148070</td>\n",
              "      <td>/m22s7zvkVFDU9ir56PiiqIEWFdT.jpg</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[{'iso_3166_1': 'KR', 'name': 'South Korea'}]</td>\n",
              "      <td>2/5/09</td>\n",
              "      <td>118.0</td>\n",
              "      <td>[{'iso_639_1': 'ko', 'name': '한국어/조선말'}]</td>\n",
              "      <td>Released</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Marine Boy</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[{'cast_id': 3, 'character': 'Chun-soo', 'cred...</td>\n",
              "      <td>[{'credit_id': '52fe464b9251416c75073b43', 'de...</td>\n",
              "      <td>3923970</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "aWsY7DVyimZi",
        "colab_type": "code",
        "colab": {},
        "outputId": "47be3ef4-c7f6-4bab-c3a6-5886a11fd62d"
      },
      "cell_type": "code",
      "source": [
        "train.info()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 3000 entries, 0 to 2999\n",
            "Data columns (total 23 columns):\n",
            "id                       3000 non-null int64\n",
            "belongs_to_collection    604 non-null object\n",
            "budget                   3000 non-null int64\n",
            "genres                   2993 non-null object\n",
            "homepage                 946 non-null object\n",
            "imdb_id                  3000 non-null object\n",
            "original_language        3000 non-null object\n",
            "original_title           3000 non-null object\n",
            "overview                 2992 non-null object\n",
            "popularity               3000 non-null float64\n",
            "poster_path              2999 non-null object\n",
            "production_companies     2844 non-null object\n",
            "production_countries     2945 non-null object\n",
            "release_date             3000 non-null object\n",
            "runtime                  2998 non-null float64\n",
            "spoken_languages         2980 non-null object\n",
            "status                   3000 non-null object\n",
            "tagline                  2403 non-null object\n",
            "title                    3000 non-null object\n",
            "Keywords                 2724 non-null object\n",
            "cast                     2987 non-null object\n",
            "crew                     2984 non-null object\n",
            "revenue                  3000 non-null int64\n",
            "dtypes: float64(2), int64(3), object(18)\n",
            "memory usage: 539.1+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "0vkxCi80imZm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Since only last two digits of year are provided, this is the correct way of getting the year.\n",
        "train[['release_month','release_day','release_year']]=train['release_date'].str.split('/',expand=True).replace(np.nan, -1).astype(int)\n",
        "# Some rows have 4 digits of year instead of 2, that's why I am applying (train['release_year'] < 100) this condition\n",
        "train.loc[ (train['release_year'] <= 19) & (train['release_year'] < 100), \"release_year\"] += 2000\n",
        "train.loc[ (train['release_year'] > 19)  & (train['release_year'] < 100), \"release_year\"] += 1900\n",
        "\n",
        "releaseDate = pd.to_datetime(train['release_date']) \n",
        "train['release_dayofweek'] = releaseDate.dt.dayofweek\n",
        "train['release_quarter'] = releaseDate.dt.quarter"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "P89EU4eHimZp",
        "colab_type": "code",
        "colab": {},
        "outputId": "f6fa277c-1924-416c-caa9-5ea38c562cb5"
      },
      "cell_type": "code",
      "source": [
        "def get_dictionary(s):\n",
        "    try:\n",
        "        d = eval(s)\n",
        "    except:\n",
        "        d = {}\n",
        "    return d\n",
        "train = train\n",
        "train['genres'] = train['genres'].map(lambda x: sorted([d['name'] for d in get_dictionary(x)])).map(lambda x: ','.join(map(str, x)))\n",
        "genres = train.genres.str.get_dummies(sep=',')\n",
        "train = pd.concat([train, genres], axis=1, sort=False)\n",
        "print(\"Action Genres Movie           \", train[train.Action == 1].shape[0])\n",
        "print(\"Adventure Genres Movie        \", train[train.Adventure == 1].shape[0])\n",
        "print(\"Animation Genres Movie        \", train[train.Animation == 1].shape[0])\n",
        "print(\"Comedy Genres Movie           \", train[train.Comedy == 1].shape[0])\n",
        "print(\"Crime Genres Movie            \", train[train.Crime == 1].shape[0])\n",
        "print(\"Documentary Genres Movie      \", train[train.Documentary == 1].shape[0])\n",
        "print(\"Drama Genres Movie            \", train[train.Drama == 1].shape[0])\n",
        "print(\"Family Genres Movie           \", train[train.Family == 1].shape[0])\n",
        "print(\"Fantasy Genres Movie          \", train[train.Fantasy == 1].shape[0])\n",
        "print(\"Foreign Genres Movie          \", train[train.Foreign == 1].shape[0])\n",
        "print(\"History Genres Movie          \", train[train.History == 1].shape[0])\n",
        "print(\"Music Genres Movie            \", train[train.Music == 1].shape[0])\n",
        "print(\"Mystery Genres Movie          \", train[train.Mystery == 1].shape[0])\n",
        "print(\"Romance Genres Movie          \", train[train.Romance == 1].shape[0])\n",
        "print(\"Science Fiction Genres Movie  \", train[train['Science Fiction'] == 1].shape[0])\n",
        "print(\"TV Movie Genres Movie         \", train[train['TV Movie'] == 1].shape[0])\n",
        "print(\"Thriller Genres Movie         \", train[train.Thriller == 1].shape[0])\n",
        "print(\"War Genres Movie              \", train[train.War == 1].shape[0])\n",
        "print(\"Western Genres Movie          \", train[train.Western == 1].shape[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Action Genres Movie            741\n",
            "Adventure Genres Movie         439\n",
            "Animation Genres Movie         141\n",
            "Comedy Genres Movie            1028\n",
            "Crime Genres Movie             469\n",
            "Documentary Genres Movie       87\n",
            "Drama Genres Movie             1531\n",
            "Family Genres Movie            260\n",
            "Fantasy Genres Movie           232\n",
            "Foreign Genres Movie           31\n",
            "History Genres Movie           132\n",
            "Music Genres Movie             100\n",
            "Mystery Genres Movie           225\n",
            "Romance Genres Movie           571\n",
            "Science Fiction Genres Movie   290\n",
            "TV Movie Genres Movie          1\n",
            "Thriller Genres Movie          789\n",
            "War Genres Movie               100\n",
            "Western Genres Movie           43\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "5ECXJ_QoimZw",
        "colab_type": "code",
        "colab": {},
        "outputId": "2f1fcaa2-4a28-4ccf-c8c5-55af63d8d423"
      },
      "cell_type": "code",
      "source": [
        "test = test\n",
        "test['genres'] = test['genres'].map(lambda x: sorted([d['name'] for d in get_dictionary(x)])).map(lambda x: ','.join(map(str, x)))\n",
        "genres = test.genres.str.get_dummies(sep=',')\n",
        "test = pd.concat([test, genres], axis=1, sort=False)\n",
        "print(\"Action Genres Movie           \", test[test.Action == 1].shape[0])\n",
        "print(\"Adventure Genres Movie        \", test[test.Adventure == 1].shape[0])\n",
        "print(\"Animation Genres Movie        \", test[test.Animation == 1].shape[0])\n",
        "print(\"Comedy Genres Movie           \", test[test.Comedy == 1].shape[0])\n",
        "print(\"Crime Genres Movie            \", test[test.Crime == 1].shape[0])\n",
        "print(\"Documentary Genres Movie      \", test[test.Documentary == 1].shape[0])\n",
        "print(\"Drama Genres Movie            \", test[test.Drama == 1].shape[0])\n",
        "print(\"Family Genres Movie           \", test[test.Family == 1].shape[0])\n",
        "print(\"Fantasy Genres Movie          \", test[test.Fantasy == 1].shape[0])\n",
        "print(\"Foreign Genres Movie          \", test[test.Foreign == 1].shape[0])\n",
        "print(\"History Genres Movie          \", test[test.History == 1].shape[0])\n",
        "print(\"Music Genres Movie            \", test[test.Music == 1].shape[0])\n",
        "print(\"Mystery Genres Movie          \", test[test.Mystery == 1].shape[0])\n",
        "print(\"Romance Genres Movie          \", test[test.Romance == 1].shape[0])\n",
        "print(\"Science Fiction Genres Movie  \", test[test['Science Fiction'] == 1].shape[0])\n",
        "print(\"TV Movie Genres Movie          0\")\n",
        "print(\"Thriller Genres Movie         \", test[test.Thriller == 1].shape[0])\n",
        "print(\"War Genres Movie              \", test[test.War == 1].shape[0])\n",
        "print(\"Western Genres Movie          \", test[test.Western == 1].shape[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Action Genres Movie            994\n",
            "Adventure Genres Movie         677\n",
            "Animation Genres Movie         241\n",
            "Comedy Genres Movie            1577\n",
            "Crime Genres Movie             615\n",
            "Documentary Genres Movie       134\n",
            "Drama Genres Movie             2145\n",
            "Family Genres Movie            415\n",
            "Fantasy Genres Movie           396\n",
            "Foreign Genres Movie           53\n",
            "History Genres Movie           163\n",
            "Music Genres Movie             167\n",
            "Mystery Genres Movie           325\n",
            "Romance Genres Movie           864\n",
            "Science Fiction Genres Movie   454\n",
            "TV Movie Genres Movie          0\n",
            "Thriller Genres Movie          1080\n",
            "War Genres Movie               143\n",
            "Western Genres Movie           74\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "eUEKLK-5imZ2",
        "colab_type": "code",
        "colab": {},
        "outputId": "f6f4dde3-49cb-41bb-a371-01a45d365583"
      },
      "cell_type": "code",
      "source": [
        "def prepare(df):\n",
        "    global json_cols\n",
        "    global train_dict\n",
        "\n",
        "    df[['release_month','release_day','release_year']]=df['release_date'].str.split('/',expand=True).replace(np.nan, 0).astype(int)\n",
        "    df['release_year'] = df['release_year']\n",
        "    df.loc[ (df['release_year'] <= 19) & (df['release_year'] < 100), \"release_year\"] += 2000\n",
        "    df.loc[ (df['release_year'] > 19)  & (df['release_year'] < 100), \"release_year\"] += 1900\n",
        "    \n",
        "    releaseDate = pd.to_datetime(df['release_date']) \n",
        "    df['release_dayofweek'] = releaseDate.dt.dayofweek \n",
        "    df['release_quarter'] = releaseDate.dt.quarter     \n",
        "    \n",
        "    rating_na = df.groupby([\"release_year\",\"original_language\"])['rating'].mean().reset_index()\n",
        "    df[df.rating.isna()]['rating'] = df.merge(rating_na, how = 'left' ,on = [\"release_year\",\"original_language\"])\n",
        "    vote_count_na = df.groupby([\"release_year\",\"original_language\"])['totalVotes'].mean().reset_index()\n",
        "    df[df.totalVotes.isna()]['totalVotes'] = df.merge(vote_count_na, how = 'left' ,on = [\"release_year\",\"original_language\"])\n",
        "    #df['rating'] = df['rating'].fillna(1.5)\n",
        "    #df['totalVotes'] = df['totalVotes'].fillna(6)\n",
        "    df['weightedRating'] = ( df['rating']*df['totalVotes'] + 6.367 * 1000 ) / ( df['totalVotes'] + 1000 )\n",
        "\n",
        "\n",
        "    df['originalBudget'] = df['budget']\n",
        "    df['inflationBudget'] = df['budget'] + df['budget']*1.8/100*(2018-df['release_year']) #Inflation simple formula\n",
        "    df['budget'] = np.log1p(df['budget']) \n",
        "    \n",
        "    \n",
        "    # Thanks to this Kernel for the next 7 features https://www.kaggle.com/artgor/eda-feature-engineering-and-model-interpretation\n",
        "    df['genders_0_crew'] = df['crew'].apply(lambda x: sum([1 for i in x if i['gender'] == 0]))\n",
        "    df['genders_1_crew'] = df['crew'].apply(lambda x: sum([1 for i in x if i['gender'] == 1]))\n",
        "    df['genders_2_crew'] = df['crew'].apply(lambda x: sum([1 for i in x if i['gender'] == 2]))\n",
        "    df['_collection_name'] = df['belongs_to_collection'].apply(lambda x: x[0]['name'] if x != {} else 0)\n",
        "    le = LabelEncoder()\n",
        "    le.fit(list(df['_collection_name'].fillna('')))\n",
        "    df['_collection_name'] = le.transform(df['_collection_name'].fillna('').astype(str))\n",
        "    df['_num_Keywords'] = df['Keywords'].apply(lambda x: len(x) if x != {} else 0)\n",
        "    df['_num_cast'] = df['cast'].apply(lambda x: len(x) if x != {} else 0)\n",
        "\n",
        "    \n",
        "    \n",
        "    df['_popularity_mean_year'] = df['popularity'] / df.groupby(\"release_year\")[\"popularity\"].transform('mean')\n",
        "    df['_budget_runtime_ratio'] = df['budget']/df['runtime'] \n",
        "    df['_budget_popularity_ratio'] = df['budget']/df['popularity']\n",
        "    df['_budget_year_ratio'] = df['budget']/(df['release_year']*df['release_year'])\n",
        "    df['_releaseYear_popularity_ratio'] = df['release_year']/df['popularity']\n",
        "    df['_releaseYear_popularity_ratio2'] = df['popularity']/df['release_year']\n",
        "\n",
        "    df['_popularity_totalVotes_ratio'] = df['totalVotes']/df['popularity']\n",
        "    df['_rating_popularity_ratio'] = df['rating']/df['popularity']\n",
        "    df['_rating_totalVotes_ratio'] = df['totalVotes']/df['rating']\n",
        "    df['_totalVotes_releaseYear_ratio'] = df['totalVotes']/df['release_year']\n",
        "    df['_budget_rating_ratio'] = df['budget']/df['rating']\n",
        "    df['_runtime_rating_ratio'] = df['runtime']/df['rating']\n",
        "    df['_budget_totalVotes_ratio'] = df['budget']/df['totalVotes']\n",
        "    \n",
        "    df['has_homepage'] = 1\n",
        "    df.loc[pd.isnull(df['homepage']) ,\"has_homepage\"] = 0\n",
        "    \n",
        "    df['isbelongs_to_collectionNA'] = 0\n",
        "    df.loc[pd.isnull(df['belongs_to_collection']) ,\"isbelongs_to_collectionNA\"] = 1\n",
        "    \n",
        "    df['isTaglineNA'] = 0\n",
        "    df.loc[df['tagline'] == 0 ,\"isTaglineNA\"] = 1 \n",
        "\n",
        "    df['isOriginalLanguageEng'] = 0 \n",
        "    df.loc[ df['original_language'] == \"en\" ,\"isOriginalLanguageEng\"] = 1\n",
        "    \n",
        "    df['isTitleDifferent'] = 1\n",
        "    df.loc[ df['original_title'] == df['title'] ,\"isTitleDifferent\"] = 0 \n",
        "\n",
        "    df['isMovieReleased'] = 1\n",
        "    df.loc[ df['status'] != \"Released\" ,\"isMovieReleased\"] = 0 \n",
        "\n",
        "    # get collection id\n",
        "    df['collection_id'] = df['belongs_to_collection'].apply(lambda x : np.nan if len(x)==0 else x[0]['id'])\n",
        "    \n",
        "    df['original_title_letter_count'] = df['original_title'].str.len() \n",
        "    df['original_title_word_count'] = df['original_title'].str.split().str.len() \n",
        "\n",
        "\n",
        "    df['title_word_count'] = df['title'].str.split().str.len()\n",
        "    df['overview_word_count'] = df['overview'].str.split().str.len()\n",
        "    df['tagline_word_count'] = df['tagline'].str.split().str.len()\n",
        "    \n",
        "    df['production_countries_count'] = df['production_countries'].apply(lambda x : len(x))\n",
        "    df['production_companies_count'] = df['production_companies'].apply(lambda x : len(x))\n",
        "    df['cast_count'] = df['cast'].apply(lambda x : len(x))\n",
        "    df['crew_count'] = df['crew'].apply(lambda x : len(x))\n",
        "    \n",
        "\n",
        "    df['meanruntimeByYear'] = df.groupby(\"release_year\")[\"runtime\"].aggregate('mean')\n",
        "    df['meanPopularityByYear'] = df.groupby(\"release_year\")[\"popularity\"].aggregate('mean')\n",
        "    df['meanBudgetByYear'] = df.groupby(\"release_year\")[\"budget\"].aggregate('mean')\n",
        "    df['meantotalVotesByYear'] = df.groupby(\"release_year\")[\"totalVotes\"].aggregate('mean')\n",
        "    df['meanTotalVotesByRating'] = df.groupby(\"rating\")[\"totalVotes\"].aggregate('mean')\n",
        "    df['medianBudgetByYear'] = df.groupby(\"release_year\")[\"budget\"].aggregate('median')\n",
        "\n",
        "    for col in ['genres', 'production_countries', 'spoken_languages', 'production_companies'] :\n",
        "        df[col] = df[col].map(lambda x: sorted(list(set([n if n in train_dict[col] else col+'_etc' for n in [d['name'] for d in x]])))).map(lambda x: ','.join(map(str, x)))\n",
        "        temp = df[col].str.get_dummies(sep=',')\n",
        "        df = pd.concat([df, temp], axis=1, sort=False)\n",
        "    df.drop(['genres_etc'], axis = 1, inplace = True)\n",
        "    \n",
        "    df = df.drop(['id', 'revenue','belongs_to_collection','genres','homepage','imdb_id','overview','runtime'\n",
        "    ,'poster_path','production_companies','production_countries','release_date','spoken_languages'\n",
        "    ,'status','title','Keywords','cast','crew','original_language','original_title','tagline', 'collection_id'\n",
        "    ],axis=1)\n",
        "    \n",
        "    df.fillna(value=0.0, inplace = True) \n",
        "\n",
        "    return df\n",
        "train = pd.read_csv('../input/tmdb-box-office-prediction/train.csv')\n",
        "\n",
        "#power_six = train.id[train.budget > 1000][train.revenue < 100]\n",
        "\n",
        "#for k in power_six :\n",
        "#    train.loc[train['id'] == k,'revenue'] =  train.loc[train['id'] == k,'revenue'] * 1000000\n",
        "#Clean Datapower_six \n",
        " \n",
        "train.loc[train['id'] == 16,'revenue'] = 192864          # Skinning\n",
        "train.loc[train['id'] == 90,'budget'] = 30000000         # Sommersby          \n",
        "train.loc[train['id'] == 118,'budget'] = 60000000        # Wild Hogs\n",
        "train.loc[train['id'] == 149,'budget'] = 18000000        # Beethoven\n",
        "train.loc[train['id'] == 313,'revenue'] = 12000000       # The Cookout \n",
        "train.loc[train['id'] == 451,'revenue'] = 12000000       # Chasing Liberty\n",
        "train.loc[train['id'] == 464,'budget'] = 20000000        # Parenthood\n",
        "train.loc[train['id'] == 470,'budget'] = 13000000        # The Karate Kid, Part II\n",
        "train.loc[train['id'] == 513,'budget'] = 930000          # From Prada to Nada\n",
        "train.loc[train['id'] == 797,'budget'] = 8000000         # Welcome to Dongmakgol\n",
        "train.loc[train['id'] == 819,'budget'] = 90000000        # Alvin and the Chipmunks: The Road Chip\n",
        "train.loc[train['id'] == 850,'budget'] = 90000000        # Modern Times\n",
        "train.loc[train['id'] == 1007,'budget'] = 2              # Zyzzyx Road \n",
        "train.loc[train['id'] == 1112,'budget'] = 7500000        # An Officer and a Gentleman\n",
        "train.loc[train['id'] == 1131,'budget'] = 4300000        # Smokey and the Bandit   \n",
        "train.loc[train['id'] == 1359,'budget'] = 10000000       # Stir Crazy \n",
        "train.loc[train['id'] == 1542,'budget'] = 1              # All at Once\n",
        "train.loc[train['id'] == 1570,'budget'] = 15800000       # Crocodile Dundee II\n",
        "train.loc[train['id'] == 1571,'budget'] = 4000000        # Lady and the Tramp\n",
        "train.loc[train['id'] == 1714,'budget'] = 46000000       # The Recruit\n",
        "train.loc[train['id'] == 1721,'budget'] = 17500000       # Cocoon\n",
        "train.loc[train['id'] == 1865,'revenue'] = 25000000      # Scooby-Doo 2: Monsters Unleashed\n",
        "train.loc[train['id'] == 1885,'budget'] = 12             # In the Cut\n",
        "train.loc[train['id'] == 2091,'budget'] = 10             # Deadfall\n",
        "train.loc[train['id'] == 2268,'budget'] = 17500000       # Madea Goes to Jail budget\n",
        "train.loc[train['id'] == 2491,'budget'] = 6              # Never Talk to Strangers\n",
        "train.loc[train['id'] == 2602,'budget'] = 31000000       # Mr. Holland's Opus\n",
        "train.loc[train['id'] == 2612,'budget'] = 15000000       # Field of Dreams\n",
        "train.loc[train['id'] == 2696,'budget'] = 10000000       # Nurse 3-D\n",
        "train.loc[train['id'] == 2801,'budget'] = 10000000       # Fracture\n",
        "train.loc[train['id'] == 335,'budget'] = 2 \n",
        "train.loc[train['id'] == 348,'budget'] = 12\n",
        "train.loc[train['id'] == 470,'budget'] = 13000000 \n",
        "train.loc[train['id'] == 513,'budget'] = 1100000\n",
        "train.loc[train['id'] == 640,'budget'] = 6 \n",
        "train.loc[train['id'] == 696,'budget'] = 1\n",
        "train.loc[train['id'] == 797,'budget'] = 8000000 \n",
        "train.loc[train['id'] == 850,'budget'] = 1500000\n",
        "train.loc[train['id'] == 1199,'budget'] = 5 \n",
        "train.loc[train['id'] == 1282,'budget'] = 9               # Death at a Funeral\n",
        "train.loc[train['id'] == 1347,'budget'] = 1\n",
        "train.loc[train['id'] == 1755,'budget'] = 2\n",
        "train.loc[train['id'] == 1801,'budget'] = 5\n",
        "train.loc[train['id'] == 1918,'budget'] = 592 \n",
        "train.loc[train['id'] == 2033,'budget'] = 4\n",
        "train.loc[train['id'] == 2118,'budget'] = 344 \n",
        "train.loc[train['id'] == 2252,'budget'] = 130\n",
        "train.loc[train['id'] == 2256,'budget'] = 1 \n",
        "train.loc[train['id'] == 2696,'budget'] = 10000000\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "test = pd.read_csv('../input/tmdb-box-office-prediction/test.csv')\n",
        "\n",
        "#Clean Data\n",
        "test.loc[test['id'] == 6733,'budget'] = 5000000\n",
        "test.loc[test['id'] == 3889,'budget'] = 15000000\n",
        "test.loc[test['id'] == 6683,'budget'] = 50000000\n",
        "test.loc[test['id'] == 5704,'budget'] = 4300000\n",
        "test.loc[test['id'] == 6109,'budget'] = 281756\n",
        "test.loc[test['id'] == 7242,'budget'] = 10000000\n",
        "test.loc[test['id'] == 7021,'budget'] = 17540562       #  Two Is a Family\n",
        "test.loc[test['id'] == 5591,'budget'] = 4000000        # The Orphanage\n",
        "test.loc[test['id'] == 4282,'budget'] = 20000000       # Big Top Pee-wee\n",
        "test.loc[test['id'] == 3033,'budget'] = 250 \n",
        "test.loc[test['id'] == 3051,'budget'] = 50\n",
        "test.loc[test['id'] == 3084,'budget'] = 337\n",
        "test.loc[test['id'] == 3224,'budget'] = 4  \n",
        "test.loc[test['id'] == 3594,'budget'] = 25  \n",
        "test.loc[test['id'] == 3619,'budget'] = 500  \n",
        "test.loc[test['id'] == 3831,'budget'] = 3  \n",
        "test.loc[test['id'] == 3935,'budget'] = 500  \n",
        "test.loc[test['id'] == 4049,'budget'] = 995946 \n",
        "test.loc[test['id'] == 4424,'budget'] = 3  \n",
        "test.loc[test['id'] == 4460,'budget'] = 8  \n",
        "test.loc[test['id'] == 4555,'budget'] = 1200000 \n",
        "test.loc[test['id'] == 4624,'budget'] = 30 \n",
        "test.loc[test['id'] == 4645,'budget'] = 500 \n",
        "test.loc[test['id'] == 4709,'budget'] = 450 \n",
        "test.loc[test['id'] == 4839,'budget'] = 7\n",
        "test.loc[test['id'] == 3125,'budget'] = 25 \n",
        "test.loc[test['id'] == 3142,'budget'] = 1\n",
        "test.loc[test['id'] == 3201,'budget'] = 450\n",
        "test.loc[test['id'] == 3222,'budget'] = 6\n",
        "test.loc[test['id'] == 3545,'budget'] = 38\n",
        "test.loc[test['id'] == 3670,'budget'] = 18\n",
        "test.loc[test['id'] == 3792,'budget'] = 19\n",
        "test.loc[test['id'] == 3881,'budget'] = 7\n",
        "test.loc[test['id'] == 3969,'budget'] = 400\n",
        "test.loc[test['id'] == 4196,'budget'] = 6\n",
        "test.loc[test['id'] == 4221,'budget'] = 11\n",
        "test.loc[test['id'] == 4222,'budget'] = 500\n",
        "test.loc[test['id'] == 4285,'budget'] = 11\n",
        "test.loc[test['id'] == 4319,'budget'] = 1\n",
        "test.loc[test['id'] == 4639,'budget'] = 10\n",
        "test.loc[test['id'] == 4719,'budget'] = 45\n",
        "test.loc[test['id'] == 4822,'budget'] = 22\n",
        "test.loc[test['id'] == 4829,'budget'] = 20\n",
        "test.loc[test['id'] == 4969,'budget'] = 20\n",
        "test.loc[test['id'] == 5021,'budget'] = 40 \n",
        "test.loc[test['id'] == 5035,'budget'] = 1 \n",
        "test.loc[test['id'] == 5063,'budget'] = 14 \n",
        "test.loc[test['id'] == 5119,'budget'] = 2 \n",
        "test.loc[test['id'] == 5214,'budget'] = 30 \n",
        "test.loc[test['id'] == 5221,'budget'] = 50 \n",
        "test.loc[test['id'] == 4903,'budget'] = 15\n",
        "test.loc[test['id'] == 4983,'budget'] = 3\n",
        "test.loc[test['id'] == 5102,'budget'] = 28\n",
        "test.loc[test['id'] == 5217,'budget'] = 75\n",
        "test.loc[test['id'] == 5224,'budget'] = 3 \n",
        "test.loc[test['id'] == 5469,'budget'] = 20 \n",
        "test.loc[test['id'] == 5840,'budget'] = 1 \n",
        "test.loc[test['id'] == 5960,'budget'] = 30\n",
        "test.loc[test['id'] == 6506,'budget'] = 11 \n",
        "test.loc[test['id'] == 6553,'budget'] = 280\n",
        "test.loc[test['id'] == 6561,'budget'] = 7\n",
        "test.loc[test['id'] == 6582,'budget'] = 218\n",
        "test.loc[test['id'] == 6638,'budget'] = 5\n",
        "test.loc[test['id'] == 6749,'budget'] = 8 \n",
        "test.loc[test['id'] == 6759,'budget'] = 50 \n",
        "test.loc[test['id'] == 6856,'budget'] = 10\n",
        "test.loc[test['id'] == 6858,'budget'] =  100\n",
        "test.loc[test['id'] == 6876,'budget'] =  250\n",
        "test.loc[test['id'] == 6972,'budget'] = 1\n",
        "test.loc[test['id'] == 7079,'budget'] = 8000000\n",
        "test.loc[test['id'] == 7150,'budget'] = 118\n",
        "test.loc[test['id'] == 6506,'budget'] = 118\n",
        "test.loc[test['id'] == 7225,'budget'] = 6\n",
        "test.loc[test['id'] == 7231,'budget'] = 85\n",
        "test.loc[test['id'] == 5222,'budget'] = 5\n",
        "test.loc[test['id'] == 5322,'budget'] = 90\n",
        "test.loc[test['id'] == 5350,'budget'] = 70\n",
        "test.loc[test['id'] == 5378,'budget'] = 10\n",
        "test.loc[test['id'] == 5545,'budget'] = 80\n",
        "test.loc[test['id'] == 5810,'budget'] = 8\n",
        "test.loc[test['id'] == 5926,'budget'] = 300\n",
        "test.loc[test['id'] == 5927,'budget'] = 4\n",
        "test.loc[test['id'] == 5986,'budget'] = 1\n",
        "test.loc[test['id'] == 6053,'budget'] = 20\n",
        "test.loc[test['id'] == 6104,'budget'] = 1\n",
        "test.loc[test['id'] == 6130,'budget'] = 30\n",
        "test.loc[test['id'] == 6301,'budget'] = 150\n",
        "test.loc[test['id'] == 6276,'budget'] = 100\n",
        "test.loc[test['id'] == 6473,'budget'] = 100\n",
        "test.loc[test['id'] == 6842,'budget'] = 30\n",
        "\n",
        "\n",
        "test['revenue'] = np.nan\n",
        "\n",
        "# features from https://www.kaggle.com/kamalchhirang/eda-simple-feature-engineering-external-data\n",
        "train = pd.merge(train, pd.read_csv('../input/tmdb-competition-additional-features/TrainAdditionalFeatures.csv'), how='left', on=['imdb_id'])\n",
        "test = pd.merge(test, pd.read_csv('../input/tmdb-competition-additional-features/TestAdditionalFeatures.csv'), how='left', on=['imdb_id'])\n",
        "\n",
        "additionalTrainData = pd.read_csv('../input/tmdb-box-office-prediction-more-training-data/additionalTrainData.csv')\n",
        "additionalTrainData['release_date'] = additionalTrainData['release_date'].astype('str')\n",
        "additionalTrainData['release_date'] = additionalTrainData['release_date'].str.replace('-', '/')\n",
        "train = pd.concat([train, additionalTrainData])\n",
        "\n",
        "#train = pd.merge(train, additionalTrainData, how='left', on=['imdb_id'],axis=1)\n",
        "print(train.columns)\n",
        "print(train.shape)\n",
        "train['revenue'] = np.log1p(train['revenue'])\n",
        "y_train = train['revenue'].values\n",
        "\n",
        "json_cols = ['genres', 'production_companies', 'production_countries', 'spoken_languages', 'Keywords', 'cast', 'crew']\n",
        "\n",
        "def get_dictionary(s):\n",
        "    try:\n",
        "        d = eval(s)\n",
        "    except:\n",
        "        d = {}\n",
        "    return d\n",
        "\n",
        "for col in tqdm(json_cols + ['belongs_to_collection']) :\n",
        "    train[col] = train[col].apply(lambda x : get_dictionary(x))\n",
        "    test[col] = test[col].apply(lambda x : get_dictionary(x))\n",
        "    \n",
        "def get_json_dict(df) :\n",
        "    global json_cols\n",
        "    result = dict()\n",
        "    for e_col in json_cols :\n",
        "        d = dict()\n",
        "        rows = df[e_col].values\n",
        "        for row in rows :\n",
        "            if row is None : continue\n",
        "            for i in row :\n",
        "                if i['name'] not in d :\n",
        "                    d[i['name']] = 0\n",
        "                d[i['name']] += 1\n",
        "        result[e_col] = d\n",
        "    return result\n",
        "\n",
        "train_dict = get_json_dict(train)\n",
        "test_dict = get_json_dict(test)\n",
        "\n",
        "# remove cateogry with bias and low frequency\n",
        "for col in json_cols :\n",
        "    \n",
        "    remove = []\n",
        "    train_id = set(list(train_dict[col].keys()))\n",
        "    test_id = set(list(test_dict[col].keys()))   \n",
        "    \n",
        "    remove += list(train_id - test_id) + list(test_id - train_id)\n",
        "    for i in train_id.union(test_id) - set(remove) :\n",
        "        if train_dict[col][i] < 10 or i == '' :\n",
        "            remove += [i]\n",
        "            \n",
        "    for i in remove :\n",
        "        if i in train_dict[col] :\n",
        "            del train_dict[col][i]\n",
        "        if i in test_dict[col] :\n",
        "            del test_dict[col][i]\n",
        "            \n",
        "all_data = prepare(pd.concat([train, test]).reset_index(drop = True))\n",
        "train = all_data.loc[:train.shape[0] - 1,:]\n",
        "test = all_data.loc[train.shape[0]:,:] "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " 12%|█▎        | 1/8 [00:00<00:01,  5.73it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Index(['Keywords', 'belongs_to_collection', 'budget', 'cast', 'crew', 'genres',\n",
            "       'homepage', 'id', 'imdb_id', 'original_language', 'original_title',\n",
            "       'overview', 'popularity', 'popularity2', 'poster_path',\n",
            "       'production_companies', 'production_countries', 'rating',\n",
            "       'release_date', 'revenue', 'runtime', 'spoken_languages', 'status',\n",
            "       'tagline', 'title', 'totalVotes'],\n",
            "      dtype='object')\n",
            "(5001, 26)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 8/8 [00:09<00:00,  1.18s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "b2RjvhzOimZ_",
        "colab_type": "code",
        "colab": {},
        "outputId": "e1e445d8-2adc-4b8f-b970-359add8331d7"
      },
      "cell_type": "code",
      "source": [
        "#y_train = train['revenue']\n",
        "#del train['revenue']\n",
        "#train['revenue']\n",
        "\n",
        "y_train.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5001,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "LeqHZMvhimaE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def divide_on_feature(X, feature_i, threshold):\n",
        "    \"\"\" Divide dataset based on if sample value on feature index is larger than\n",
        "        the given threshold \"\"\"\n",
        "    split_func = None\n",
        "    if isinstance(threshold, int) or isinstance(threshold, float):\n",
        "        split_func = lambda sample: sample[feature_i] >= threshold\n",
        "    else:\n",
        "        split_func = lambda sample: sample[feature_i] == threshold\n",
        "\n",
        "    X_1 = np.array([sample for sample in X if split_func(sample)])\n",
        "    X_2 = np.array([sample for sample in X if not split_func(sample)])\n",
        "\n",
        "    return np.array([X_1, X_2])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "goEWkyUYimaG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class DecisionNode():\n",
        "    \"\"\"Class that represents a decision node or leaf in the decision tree\n",
        "    Parameters:\n",
        "    -----------\n",
        "    feature_i: int\n",
        "        Feature index which we want to use as the threshold measure.\n",
        "    threshold: float\n",
        "        The value that we will compare feature values at feature_i against to\n",
        "        determine the prediction.\n",
        "    value: float\n",
        "        The class prediction if classification tree, or float value if regression tree.\n",
        "    true_branch: DecisionNode\n",
        "        Next decision node for samples where features value met the threshold.\n",
        "    false_branch: DecisionNode\n",
        "        Next decision node for samples where features value did not meet the threshold.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, feature_i=None, threshold=None,\n",
        "                 value=None, true_branch=None, false_branch=None):\n",
        "        self.feature_i = feature_i  # Index for the feature that is tested\n",
        "        self.threshold = threshold  # Threshold value for feature\n",
        "        self.value = value  # Value if the node is a leaf in the tree\n",
        "        self.true_branch = true_branch  # 'Left' subtree\n",
        "        self.false_branch = false_branch  # 'Right' subtree\n",
        "\n",
        "# Super class of RegressionTree and ClassificationTree\n",
        "class DecisionTree(object):\n",
        "    \"\"\"Super class of RegressionTree and ClassificationTree.\n",
        "    Parameters:\n",
        "    -----------\n",
        "    min_samples_split: int\n",
        "        The minimum number of samples needed to make a split when building a tree.\n",
        "    min_impurity: float\n",
        "        The minimum impurity required to split the tree further.\n",
        "    max_depth: int\n",
        "        The maximum depth of a tree.\n",
        "    loss: function\n",
        "        Loss function that is used for Gradient Boosting models to calculate impurity.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, min_samples_split=2, min_impurity=1e-7,\n",
        "                 max_depth=float(\"inf\"), loss=None):\n",
        "        self.root = None  # Root node in dec. tree\n",
        "        # Minimum n of samples to justify split\n",
        "        self.min_samples_split = min_samples_split\n",
        "        # The minimum impurity to justify split\n",
        "        self.min_impurity = min_impurity\n",
        "        # The maximum depth to grow the tree to\n",
        "        self.max_depth = max_depth\n",
        "        # Function to calculate impurity (classif.=>info gain, regr=>variance reduct.)\n",
        "        self._impurity_calculation = None\n",
        "        # Function to determine prediction of y at leaf\n",
        "        self._leaf_value_calculation = None\n",
        "        # If y is one-hot encoded (multi-dim) or not (one-dim)\n",
        "        self.one_dim = None\n",
        "        # If Gradient Boost\n",
        "        self.loss = loss\n",
        "\n",
        "    def fit(self, X, y, loss=None):\n",
        "        \"\"\" Build decision tree \"\"\"\n",
        "        self.one_dim = len(np.shape(y)) == 1\n",
        "        self.root = self._build_tree(X, y)\n",
        "        self.loss = None\n",
        "\n",
        "    def _build_tree(self, X, y, current_depth=0):\n",
        "        \"\"\" Recursive method which builds out the decision tree and splits X and respective y\n",
        "        on the feature of X which (based on impurity) best separates the data\"\"\"\n",
        "        largest_impurity = 0\n",
        "        best_criteria = None  # Feature index and threshold\n",
        "        best_sets = None  # Subsets of the data\n",
        "\n",
        "        # Check if expansion of y is needed\n",
        "        if len(np.shape(y)) == 1:\n",
        "            y = np.expand_dims(y, axis=1)\n",
        "\n",
        "        # Add y as last column of X\n",
        "        Xy = np.concatenate((X, y), axis=1)\n",
        "\n",
        "        n_samples, n_features = np.shape(X)\n",
        "\n",
        "        if n_samples >= self.min_samples_split and current_depth <= self.max_depth:\n",
        "            # Calculate the impurity for each feature\n",
        "            for feature_i in range(n_features):\n",
        "                # All values of feature_i\n",
        "                feature_values = np.expand_dims(X[:, feature_i], axis=1)\n",
        "                unique_values = np.unique(feature_values)\n",
        "\n",
        "                # Iterate through all unique values of feature column i and\n",
        "                # calculate the impurity\n",
        "                for threshold in unique_values:\n",
        "                    # Divide X and y depending on if the feature value of X at index feature_i\n",
        "                    # meets the threshold\n",
        "                    Xy1, Xy2 = divide_on_feature(Xy, feature_i, threshold)\n",
        "\n",
        "                    if len(Xy1) > 0 and len(Xy2) > 0:\n",
        "                        # Select the y-values of the two sets\n",
        "                        y1 = Xy1[:, n_features:]\n",
        "                        y2 = Xy2[:, n_features:]\n",
        "\n",
        "                        # Calculate impurity\n",
        "                        impurity = self._impurity_calculation(y, y1, y2)\n",
        "\n",
        "                        # If this threshold resulted in a higher information gain than previously\n",
        "                        # recorded save the threshold value and the feature\n",
        "                        # index\n",
        "                        if impurity > largest_impurity:\n",
        "                            largest_impurity = impurity\n",
        "                            best_criteria = {\"feature_i\": feature_i, \"threshold\": threshold}\n",
        "                            best_sets = {\n",
        "                                \"leftX\": Xy1[:, :n_features],  # X of left subtree\n",
        "                                \"lefty\": Xy1[:, n_features:],  # y of left subtree\n",
        "                                \"rightX\": Xy2[:, :n_features],  # X of right subtree\n",
        "                                \"righty\": Xy2[:, n_features:]  # y of right subtree\n",
        "                            }\n",
        "\n",
        "        if largest_impurity > self.min_impurity:\n",
        "            # Build subtrees for the right and left branches\n",
        "            true_branch = self._build_tree(best_sets[\"leftX\"], best_sets[\"lefty\"], current_depth + 1)\n",
        "            false_branch = self._build_tree(best_sets[\"rightX\"], best_sets[\"righty\"], current_depth + 1)\n",
        "            return DecisionNode(feature_i=best_criteria[\"feature_i\"], threshold=best_criteria[\n",
        "                \"threshold\"], true_branch=true_branch, false_branch=false_branch)\n",
        "\n",
        "        # We're at leaf => determine value\n",
        "        leaf_value = self._leaf_value_calculation(y)\n",
        "        return DecisionNode(value=leaf_value)\n",
        "\n",
        "    def predict_value(self, x, tree=None):\n",
        "        \"\"\" Do a recursive search down the tree and make a prediction of the data sample by the\n",
        "            value of the leaf that we end up at \"\"\"\n",
        "\n",
        "        if tree is None:\n",
        "            tree = self.root\n",
        "\n",
        "        # If we have a value (i.e we're at a leaf) => return value as the prediction\n",
        "        if tree.value is not None:\n",
        "            return tree.value\n",
        "\n",
        "        # Choose the feature that we will test\n",
        "        feature_value = x[tree.feature_i]\n",
        "\n",
        "        # Determine if we will follow left or right branch\n",
        "        branch = tree.false_branch\n",
        "        if isinstance(feature_value, int) or isinstance(feature_value, float):\n",
        "            if feature_value >= tree.threshold:\n",
        "                branch = tree.true_branch\n",
        "        elif feature_value == tree.threshold:\n",
        "            branch = tree.true_branch\n",
        "\n",
        "        # Test subtree\n",
        "        return self.predict_value(x, branch)\n",
        "\n",
        "    def predict(self, X):\n",
        "        \"\"\" Classify samples one by one and return the set of labels \"\"\"\n",
        "        y_pred = []\n",
        "        for x in X:\n",
        "            y_pred.append(self.predict_value(x))\n",
        "        return y_pred\n",
        "\n",
        "    def print_tree(self, tree=None, indent=\" \"):\n",
        "        \"\"\" Recursively print the decision tree \"\"\"\n",
        "        if not tree:\n",
        "            tree = self.root\n",
        "\n",
        "        # If we're at leaf => print the label\n",
        "        if tree.value is not None:\n",
        "            print(tree.value)\n",
        "        # Go deeper down the tree\n",
        "        else:\n",
        "            # Print test\n",
        "            print(\"%s:%s? \" % (tree.feature_i, tree.threshold))\n",
        "            # Print the true scenario\n",
        "            print(\"%sT->\" % (indent), end=\"\")\n",
        "            self.print_tree(tree.true_branch, indent + indent)\n",
        "            # Print the false scenario\n",
        "            print(\"%sF->\" % (indent), end=\"\")\n",
        "            self.print_tree(tree.false_branch, indent + indent)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "uv8HCBtaimaJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from __future__ import division, print_function\n",
        "import numpy as np\n",
        "import progressbar\n",
        "\n",
        "bar_widgets = [\n",
        "    'Training: ', progressbar.Percentage(), ' ', progressbar.Bar(marker=\"-\", left=\"[\", right=\"]\"),\n",
        "    ' ', progressbar.ETA()\n",
        "]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "k_bxLtEoimaN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class LeastSquaresLoss():\n",
        "    def gradient(self, actual, predicted):\n",
        "        return actual -  predicted\n",
        "    \n",
        "    def hess(self, actual, predicted):\n",
        "        return np.ones_like(actual)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "2lgSNMgximaS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class XGBoostRegressionTree(DecisionTree):\n",
        "    \"\"\"\n",
        "    Regression tree for XGBoost\n",
        "    - Reference -\n",
        "    http://xgboost.readthedocs.io/en/latest/model.html\n",
        "    \"\"\"\n",
        " \n",
        "    def _split(self, y):\n",
        "        \"\"\" y contains y_true in left half of the middle column and\n",
        "        y_pred in the right half. Split and return the two matrices \"\"\"\n",
        "\n",
        "        col = int(np.shape(y)[1]/2)\n",
        "        y, y_pred = y[:, :col], y[:, col:]\n",
        "        return y, y_pred\n",
        " \n",
        "    def _gain(self, y, y_pred):\n",
        "        nominator = np.power((self.loss.gradient(y, y_pred)).sum(), 2)\n",
        "        denominator = self.loss.hess(y, y_pred).sum()\n",
        "        return 0.5 * (nominator / denominator)\n",
        " \n",
        "    def _gain_by_taylor(self, y, y1, y2):\n",
        "        # Split\n",
        "        y, y_pred = self._split(y)\n",
        "        y1, y1_pred = self._split(y1)\n",
        "        y2, y2_pred = self._split(y2)\n",
        " \n",
        "        true_gain = self._gain(y1, y1_pred)\n",
        "        false_gain = self._gain(y2, y2_pred)\n",
        "        gain = self._gain(y, y_pred)\n",
        "        return true_gain + false_gain - gain\n",
        " \n",
        "    def _approximate_update(self, y):\n",
        "        # y split into y, y_pred\n",
        "        y, y_pred = self._split(y)\n",
        "        gradient = np.sum(self.loss.gradient(y, y_pred),axis=0)\n",
        "        hessian = np.sum(self.loss.hess(y, y_pred), axis=0)\n",
        "        update_approximation =  gradient / hessian\n",
        "        return update_approximation\n",
        " \n",
        " \n",
        "    def fit(self, X, y):\n",
        "        self._impurity_calculation = self._gain_by_taylor\n",
        "        self._leaf_value_calculation = self._approximate_update\n",
        "        super(XGBoostRegressionTree, self).fit(X, y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "L1yZbhIXimaW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class XGBoost(object):\n",
        "    \"\"\"The XGBoost classifier.\n",
        "    Reference: http://xgboost.readthedocs.io/en/latest/model.html\n",
        "    Parameters:\n",
        "    -----------\n",
        "    n_estimators: int\n",
        "        The number of classification trees that are used.\n",
        "    learning_rate: float\n",
        "        The step length that will be taken when following the negative gradient during\n",
        "        training.\n",
        "    min_samples_split: int\n",
        "        The minimum number of samples needed to make a split when building a tree.\n",
        "    min_impurity: float\n",
        "        The minimum impurity required to split the tree further.\n",
        "    max_depth: int\n",
        "        The maximum depth of a tree.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, n_estimators=200, learning_rate=0.01, min_samples_split=2,\n",
        "                 min_impurity=1e-7, max_depth=2):\n",
        "        self.n_estimators = n_estimators  # Number of trees\n",
        "        self.learning_rate = learning_rate  # Step size for weight update\n",
        "        self.min_samples_split = min_samples_split  # The minimum n of sampels to justify split\n",
        "        self.min_impurity = min_impurity  # Minimum variance reduction to continue\n",
        "        self.max_depth = max_depth  # Maximum depth for tree\n",
        "\n",
        "        self.bar = progressbar.ProgressBar(widgets=bar_widgets)\n",
        "\n",
        "        # Log loss for classification\n",
        "        self.loss = LeastSquaresLoss()\n",
        "\n",
        "        # Initialize regression trees\n",
        "        self.trees = []\n",
        "        for _ in range(n_estimators):\n",
        "            tree = XGBoostRegressionTree(\n",
        "                min_samples_split=self.min_samples_split,\n",
        "                min_impurity=min_impurity,\n",
        "                max_depth=self.max_depth,\n",
        "                loss=self.loss)\n",
        "\n",
        "            self.trees.append(tree)\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        # y = to_categorical(y)\n",
        "        m = X.shape[0]\n",
        "        y = np.reshape(y, (m, -1))\n",
        "        y_pred = np.zeros(np.shape(y))\n",
        "        for i in self.bar(range(self.n_estimators)):\n",
        "            tree = self.trees[i]\n",
        "            y_and_pred = np.concatenate((y, y_pred), axis=1)\n",
        "            tree.fit(X, y_and_pred)\n",
        "            update_pred = tree.predict(X)\n",
        "            update_pred = np.reshape(update_pred, (m, -1))\n",
        "            y_pred += update_pred\n",
        "\n",
        "    def predict(self, X):\n",
        "        y_pred = None\n",
        "        m = X.shape[0]\n",
        "        # Make predictions\n",
        "        for tree in self.trees:\n",
        "            # Estimate gradient and update prediction\n",
        "            update_pred = tree.predict(X)\n",
        "            update_pred = np.reshape(update_pred, (m, -1))\n",
        "            if y_pred is None:\n",
        "                y_pred = np.zeros_like(update_pred)\n",
        "            y_pred += update_pred\n",
        "\n",
        "        return y_pred"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "if2LGn_Ximag",
        "colab_type": "code",
        "colab": {},
        "outputId": "58fd043b-6e08-4674-ebd0-a49bf75b7bcf"
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "#from utils import train_test_split, standardize, to_categorical, normalize\n",
        "#from utils import mean_squared_error, accuracy_score\n",
        "#from xgboost.xgboost_model import XGBoost\n",
        "\n",
        "def main():\n",
        "    print (\"-- XGBoost --\")\n",
        "\n",
        "    # Load data\n",
        "    train_val = train.values\n",
        "    test_val = test.values\n",
        "    all_data_val = all_data.values\n",
        "    model = XGBoost()\n",
        "    model.fit(train_val, y_train)\n",
        "    y_pred = model.predict(test_val)\n",
        "\n",
        "    #y_pred_line = model.predict(all_data_val)\n",
        "    #print(test[0:5])\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r                                                                               \r\rTraining: N/A% [                                               ] ETA:  --:--:--"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "-- XGBoost --\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "Ezs2HC94imak",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}