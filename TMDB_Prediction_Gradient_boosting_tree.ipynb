{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TMDB Prediction - Gradient boosting tree.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yuqiw4/ANLY601Project/blob/master/TMDB_Prediction_Gradient_boosting_tree.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "lQgGW4odTAYi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# TMDB Box Office Prediction"
      ]
    },
    {
      "metadata": {
        "id": "ETQ8m3XzPawT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "\n",
        "import seaborn as sns \n",
        "from tqdm import tqdm\n",
        "from datetime import datetime\n",
        "import json\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zyg4BVhYR2uk",
        "colab_type": "code",
        "outputId": "a434b81a-f2df-4210-faa1-77109b2c9e1f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "h0wUyg15LBn8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Prepare Data"
      ]
    },
    {
      "metadata": {
        "id": "s7VncGYSMWeq",
        "colab_type": "code",
        "outputId": "da70b3d3-2f6b-4ff3-c80a-193e7cbaf3ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "def prepare(df):\n",
        "    global json_cols\n",
        "    global train_dict\n",
        "\n",
        "    df[['release_month','release_day','release_year']]=df['release_date'].str.split('/',expand=True).replace(np.nan, 0).astype(int)\n",
        "    df['release_year'] = df['release_year']\n",
        "    df.loc[ (df['release_year'] <= 19) & (df['release_year'] < 100), \"release_year\"] += 2000\n",
        "    df.loc[ (df['release_year'] > 19)  & (df['release_year'] < 100), \"release_year\"] += 1900\n",
        "    \n",
        "    releaseDate = pd.to_datetime(df['release_date']) \n",
        "    df['release_dayofweek'] = releaseDate.dt.dayofweek \n",
        "    df['release_quarter'] = releaseDate.dt.quarter     \n",
        "\n",
        "\n",
        "    df['originalBudget'] = df['budget']\n",
        "    df['inflationBudget'] = df['budget'] + df['budget']*1.8/100*(2018-df['release_year']) #Inflation simple formula\n",
        "    df['budget'] = np.log1p(df['budget']) \n",
        "    \n",
        "    \n",
        "    # Thanks to this Kernel for the next 7 features https://www.kaggle.com/artgor/eda-feature-engineering-and-model-interpretation\n",
        "    df['genders_0_crew'] = df['crew'].apply(lambda x: sum([1 for i in x if i['gender'] == 0]))\n",
        "    df['genders_1_crew'] = df['crew'].apply(lambda x: sum([1 for i in x if i['gender'] == 1]))\n",
        "    df['genders_2_crew'] = df['crew'].apply(lambda x: sum([1 for i in x if i['gender'] == 2]))\n",
        "    df['_collection_name'] = df['belongs_to_collection'].apply(lambda x: x[0]['name'] if x != {} else 0)\n",
        "    le = LabelEncoder()\n",
        "    le.fit(list(df['_collection_name'].fillna('')))\n",
        "    df['_collection_name'] = le.transform(df['_collection_name'].fillna('').astype(str))\n",
        "    df['_num_Keywords'] = df['Keywords'].apply(lambda x: len(x) if x != {} else 0)\n",
        "    df['_num_cast'] = df['cast'].apply(lambda x: len(x) if x != {} else 0)\n",
        "\n",
        "    \n",
        "    \n",
        "    df['_popularity_mean_year'] = df['popularity'] / df.groupby(\"release_year\")[\"popularity\"].transform('mean')\n",
        "    df['_budget_runtime_ratio'] = df['budget']/df['runtime'] \n",
        "    df['_budget_popularity_ratio'] = df['budget']/df['popularity']\n",
        "    df['_budget_year_ratio'] = df['budget']/(df['release_year']*df['release_year'])\n",
        "    df['_releaseYear_popularity_ratio'] = df['release_year']/df['popularity']\n",
        "    df['_releaseYear_popularity_ratio2'] = df['popularity']/df['release_year']\n",
        "\n",
        "    df['has_homepage'] = 1\n",
        "    df.loc[pd.isnull(df['homepage']) ,\"has_homepage\"] = 0\n",
        "    \n",
        "    df['isbelongs_to_collectionNA'] = 0\n",
        "    df.loc[pd.isnull(df['belongs_to_collection']) ,\"isbelongs_to_collectionNA\"] = 1\n",
        "    \n",
        "    df['isTaglineNA'] = 0\n",
        "    df.loc[df['tagline'] == 0 ,\"isTaglineNA\"] = 1 \n",
        "\n",
        "    df['isOriginalLanguageEng'] = 0 \n",
        "    df.loc[ df['original_language'] == \"en\" ,\"isOriginalLanguageEng\"] = 1\n",
        "    \n",
        "    df['isTitleDifferent'] = 1\n",
        "    df.loc[ df['original_title'] == df['title'] ,\"isTitleDifferent\"] = 0 \n",
        "\n",
        "    df['isMovieReleased'] = 1\n",
        "    df.loc[ df['status'] != \"Released\" ,\"isMovieReleased\"] = 0 \n",
        "\n",
        "    # get collection id\n",
        "    df['collection_id'] = df['belongs_to_collection'].apply(lambda x : np.nan if len(x)==0 else x[0]['id'])\n",
        "    \n",
        "    df['original_title_letter_count'] = df['original_title'].str.len() \n",
        "    df['original_title_word_count'] = df['original_title'].str.split().str.len() \n",
        "\n",
        "\n",
        "    df['title_word_count'] = df['title'].str.split().str.len()\n",
        "    df['overview_word_count'] = df['overview'].str.split().str.len()\n",
        "    df['tagline_word_count'] = df['tagline'].str.split().str.len()\n",
        "    \n",
        "    df['production_countries_count'] = df['production_countries'].apply(lambda x : len(x))\n",
        "    df['production_companies_count'] = df['production_companies'].apply(lambda x : len(x))\n",
        "    df['cast_count'] = df['cast'].apply(lambda x : len(x))\n",
        "    df['crew_count'] = df['crew'].apply(lambda x : len(x))\n",
        "    \n",
        "\n",
        "    df['meanruntimeByYear'] = df.groupby(\"release_year\")[\"runtime\"].aggregate('mean')\n",
        "    df['meanPopularityByYear'] = df.groupby(\"release_year\")[\"popularity\"].aggregate('mean')\n",
        "    df['meanBudgetByYear'] = df.groupby(\"release_year\")[\"budget\"].aggregate('mean')\n",
        "    df['medianBudgetByYear'] = df.groupby(\"release_year\")[\"budget\"].aggregate('median')\n",
        "\n",
        "    for col in ['genres', 'production_countries', 'spoken_languages', 'production_companies'] :\n",
        "        df[col] = df[col].map(lambda x: sorted(list(set([n if n in train_dict[col] else col+'_etc' for n in [d['name'] for d in x]])))).map(lambda x: ','.join(map(str, x)))\n",
        "        temp = df[col].str.get_dummies(sep=',')\n",
        "        df = pd.concat([df, temp], axis=1, sort=False)\n",
        "    df.drop(['genres_etc'], axis = 1, inplace = True)\n",
        "    \n",
        "    df = df.drop(['id', 'revenue','belongs_to_collection','genres','homepage','imdb_id','overview','runtime'\n",
        "    ,'poster_path','production_companies','production_countries','release_date','spoken_languages'\n",
        "    ,'status','title','Keywords','cast','crew','original_language','original_title','tagline', 'collection_id'\n",
        "    ],axis=1)\n",
        "    \n",
        "    df.fillna(value=0.0, inplace = True) \n",
        "\n",
        "    return df\n",
        "\n",
        "  \n",
        "train = pd.read_csv('drive/My Drive/Colab Notebooks/train.csv')\n",
        "test = pd.read_csv('drive/My Drive/Colab Notebooks/test.csv')\n",
        "\n",
        "test['revenue'] = np.nan\n",
        "\n",
        "y_train = train['revenue'].values\n",
        "\n",
        "\n",
        "json_cols = ['genres', 'production_companies', 'production_countries', 'spoken_languages', 'Keywords', 'cast', 'crew']\n",
        "\n",
        "def get_dictionary(s):\n",
        "    try:\n",
        "        d = eval(s)\n",
        "    except:\n",
        "        d = {}\n",
        "    return d\n",
        "\n",
        "for col in tqdm(json_cols + ['belongs_to_collection']) :\n",
        "    train[col] = train[col].apply(lambda x : get_dictionary(x))\n",
        "    test[col] = test[col].apply(lambda x : get_dictionary(x))\n",
        "    \n",
        "def get_json_dict(df) :\n",
        "    global json_cols\n",
        "    result = dict()\n",
        "    for e_col in json_cols :\n",
        "        d = dict()\n",
        "        rows = df[e_col].values\n",
        "        for row in rows :\n",
        "            if row is None : continue\n",
        "            for i in row :\n",
        "                if i['name'] not in d :\n",
        "                    d[i['name']] = 0\n",
        "                d[i['name']] += 1\n",
        "        result[e_col] = d\n",
        "    return result\n",
        "\n",
        "train_dict = get_json_dict(train)\n",
        "test_dict = get_json_dict(test)\n",
        "\n",
        "# remove cateogry with bias and low frequency\n",
        "for col in json_cols :\n",
        "    \n",
        "    remove = []\n",
        "    train_id = set(list(train_dict[col].keys()))\n",
        "    test_id = set(list(test_dict[col].keys()))   \n",
        "    \n",
        "    remove += list(train_id - test_id) + list(test_id - train_id)\n",
        "    for i in train_id.union(test_id) - set(remove) :\n",
        "        if train_dict[col][i] < 10 or i == '' :\n",
        "            remove += [i]\n",
        "            \n",
        "    for i in remove :\n",
        "        if i in train_dict[col] :\n",
        "            del train_dict[col][i]\n",
        "        if i in test_dict[col] :\n",
        "            del test_dict[col][i]\n",
        "            \n",
        "all_data = prepare(pd.concat([train, test]).reset_index(drop = True))\n",
        "train = all_data.loc[:train.shape[0] - 1,:]\n",
        "test = all_data.loc[train.shape[0]:,:] "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 8/8 [00:06<00:00,  1.23it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "DuKhZVneMWb6",
        "colab_type": "code",
        "outputId": "0203f716-18ab-4e52-e150-774d39a6660d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "train.shape\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3000, 191)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 91
        }
      ]
    },
    {
      "metadata": {
        "id": "o7seQOV3X_S-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Evaluation metric"
      ]
    },
    {
      "metadata": {
        "id": "AkX81mQ5X87q",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "#A function to calculate Root Mean Squared Logarithmic Error (RMSLE)\n",
        "def rmsle(real, predicted):\n",
        "    sum=0.0\n",
        "    for x in range(len(predicted)):\n",
        "        if predicted[x]<0 or real[x]<0: #check for negative values\n",
        "            continue\n",
        "        p = np.log(predicted[x]+1)\n",
        "        r = np.log(real[x]+1)\n",
        "        sum = sum + (p - r)**2\n",
        "    return((sum/len(predicted))**0.5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PKAGzUiJLHwi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Gradient Boosting on our own"
      ]
    },
    {
      "metadata": {
        "id": "Qk-3FhhEWcpZ",
        "colab_type": "code",
        "outputId": "8ad025af-5e3a-4780-8e0f-29cb877a78cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "cell_type": "code",
      "source": [
        "# import the regressor \n",
        "from sklearn.tree import DecisionTreeRegressor \n",
        "\n",
        "# single decision tree\n",
        "regr_1 = DecisionTreeRegressor(max_depth=2)\n",
        "\n",
        "train = train.replace(np.inf, -1)\n",
        "\n",
        "regr_1.fit(train, y_train)\n",
        "\n",
        "predictions = regr_1.predict(train)\n",
        "\n",
        "# evaluate predictions\n",
        "print(\"MSE: %.5f\" % (mean_squared_error(y_train, predictions)))\n",
        "print(\"rmsle: %.5f\" % (rmsle(y_train, predictions)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MSE: 8456649139394109.00000\n",
            "rmsle: 3.17321\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "7uTZ3bIkK_7s",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        " \n",
        "def train_gb(train, y_train, max_n = 10, threshold = 0.001, max_depth = 5):\n",
        "  \n",
        "  train = train.replace(np.inf, -1)\n",
        "  \n",
        "  y_pre = np.zeros(y_train.shape)\n",
        "  trees = []\n",
        "  errors = []\n",
        "  n = 1\n",
        "  tree1 = DecisionTreeRegressor(random_state = n, max_depth = max_depth)\n",
        "  tree1.fit(train, y_train)\n",
        "  trees.append(tree1)\n",
        "  y_1 = tree1.predict(train)\n",
        "  y_curr = y_pre + y_1\n",
        "  error = y_train - y_curr\n",
        "  errors.append(error)\n",
        "  y_pre = y_curr\n",
        "  \n",
        "  while n < max_n and max(abs(error)) > threshold:\n",
        "    \n",
        "    n += 1\n",
        "    # create a regressor object \n",
        "    regressor = DecisionTreeRegressor(random_state = n, max_depth = max_depth)  \n",
        "  \n",
        "    # fit the regressor with X and Y data \n",
        "    regressor.fit(train, error)\n",
        "    trees.append(regressor)\n",
        "    \n",
        "    y = regressor.predict(train)\n",
        "    y_curr = y_pre + y\n",
        "    \n",
        "    error = y_train - y_curr\n",
        "    errors.append(error)\n",
        "    \n",
        "    y_pre = y_curr\n",
        "  \n",
        "  return trees, errors, y_curr\n",
        "\n",
        "def predict_gb(trees, test):\n",
        "  test = test.replace(np.inf, -1)\n",
        "  y_curr = np.zeros(test.shape[0])\n",
        "  for tree in trees:\n",
        "    y = tree.predict(test)\n",
        "    y_curr += y\n",
        "  \n",
        "  return y_curr\n",
        "  \n",
        "  \n",
        "    \n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DBO0rkm5T5K1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "trees, errors, y_curr = train_gb(train, y_train, max_n = 100, threshold = 0.001, max_depth = 5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ytnh0En_K_ha",
        "colab_type": "code",
        "outputId": "e4f2bf81-e3ca-4f82-f710-79cad209bccf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "cell_type": "code",
      "source": [
        "predictions = predict_gb(trees, train)\n",
        "\n",
        "# evaluate predictions\n",
        "print(\"MSE: %.5f\" % (mean_squared_error(y_train, predictions)))\n",
        "print(\"rmsle: %.5f\" % (rmsle(y_train, predictions)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MSE: 16406152404594.14648\n",
            "rmsle: 1.53063\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "m9aM_JyhaSfr",
        "colab_type": "code",
        "outputId": "3689aabd-f9c6-4631-af70-38f9153cf66a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "sum(predictions<0)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "323"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 97
        }
      ]
    },
    {
      "metadata": {
        "id": "UGianOW3Zaqf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### make predictions on test dataset"
      ]
    },
    {
      "metadata": {
        "id": "Nc8CJ4TiY4nl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y_test_pred = predict_gb(trees, test)\n",
        "\n",
        "for i in range(len(y_test_pred)):\n",
        "  if y_test_pred[i] < 0:\n",
        "    y_test_pred[i] = 0\n",
        "\n",
        "test_1.iloc[:,:] = test.iloc[:,:]\n",
        "test_1['revenue'] = y_test_pred\n",
        "test_1 = test_1.loc[:, ['id','revenue']]\n",
        "test_1.to_csv('drive/My Drive/Colab Notebooks/test_1.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}